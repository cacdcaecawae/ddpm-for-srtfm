import torchvision
from torch.utils.data import DataLoader, Dataset
from torchvision.transforms import Compose, Lambda, ToTensor
from PIL import Image
import torch.nn as nn
from torchvision import transforms as T
import torchvision.transforms.functional as TF
import os
import random

# å¤šè¿›ç¨‹åŠ é€Ÿéœ€è¦ï¼Œlambdaä¼šé˜»å¡å¤šè¿›ç¨‹
class ConvertToRGB(object):
    def __call__(self, image):
        return image.convert('RGB')
    
class Identity(nn.Module):
    def forward(self, x): 
        return x


class PairedTransform:
    """
    é…å¯¹å›¾åƒçš„æ•°æ®å¢å¼ºç±»
    ç¡®ä¿LRå’ŒHRå›¾åƒä½¿ç”¨ç›¸åŒçš„éšæœºå˜æ¢å‚æ•°ï¼Œä¿æŒå¯¹é½
    """
    def __init__(self, image_size, channels=1, augment=False):
        """
        Args:
            image_size: ç›®æ ‡å›¾åƒå°ºå¯¸
            channels: é€šé“æ•°ï¼ˆ1=ç°åº¦ï¼Œ3=RGBï¼‰
            augment: æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼ºï¼ˆè®­ç»ƒæ—¶Trueï¼Œè¯„ä¼°æ—¶Falseï¼‰
        """
        self.image_size = image_size
        self.channels = channels
        self.augment = augment
    
    def _convert_color(self, image):
        """é¢œè‰²è½¬æ¢ï¼ˆé¿å…ä½¿ç”¨lambdaï¼Œç¡®ä¿å¯ä»¥è¢«pickleï¼‰"""
        if self.channels == 1:
            return image  # å•é€šé“ï¼Œä¿æŒåŸæ ·
        else:
            return image.convert('RGB')  # è½¬RGB
    
    def __call__(self, lr_image, hr_image):
        """
        å¯¹LRå’ŒHRå›¾åƒåº”ç”¨ç›¸åŒçš„å˜æ¢
        
        Args:
            lr_image: PIL Image, ä½åˆ†è¾¨ç‡å›¾åƒ
            hr_image: PIL Image, é«˜åˆ†è¾¨ç‡å›¾åƒ
        
        Returns:
            lr_tensor: torch.Tensor, å˜æ¢åçš„LRå›¾åƒ
            hr_tensor: torch.Tensor, å˜æ¢åçš„HRå›¾åƒ
        """
        # 1. ç¡®å®šæ€§å˜æ¢ï¼šé¢œè‰²è½¬æ¢
        lr_image = self._convert_color(lr_image)
        hr_image = self._convert_color(hr_image)
        
        # 2. ç¡®å®šæ€§å˜æ¢ï¼šResizeå’ŒCenterCrop
        lr_image = TF.resize(lr_image, self.image_size, interpolation=Image.BICUBIC)
        hr_image = TF.resize(hr_image, self.image_size, interpolation=Image.BICUBIC)
        
        lr_image = TF.center_crop(lr_image, self.image_size)
        hr_image = TF.center_crop(hr_image, self.image_size)
        
        # 3. éšæœºå¢å¼ºå˜æ¢ï¼ˆè®­ç»ƒæ—¶ï¼‰
        if self.augment:
            # ä¸€æ¬¡æ€§é‡‡æ ·æ‰€æœ‰éšæœºå‚æ•°
            # æ°´å¹³ç¿»è½¬
            if random.random() > 0.5:
                lr_image = TF.hflip(lr_image)
                hr_image = TF.hflip(hr_image)
            
            # éšæœºå¹³ç§»ï¼ˆæœ€å¤š5%ï¼‰
            max_translate = int(0.05 * self.image_size)
            translate_x = random.randint(-max_translate, max_translate)
            translate_y = random.randint(-max_translate, max_translate)
            lr_image = TF.affine(lr_image, angle=0, translate=(translate_x, translate_y),
                                scale=1.0, shear=0, fill=0)
            hr_image = TF.affine(hr_image, angle=0, translate=(translate_x, translate_y),
                                scale=1.0, shear=0, fill=0)
        
        # 4. è½¬æ¢ä¸ºTensorå¹¶å½’ä¸€åŒ–åˆ°[-1, 1]
        lr_tensor = TF.to_tensor(lr_image)  # [0, 1]
        hr_tensor = TF.to_tensor(hr_image)  # [0, 1]
        
        lr_tensor = TF.normalize(lr_tensor, mean=[0.5]*self.channels, std=[0.5]*self.channels)  # [-1, 1]
        hr_tensor = TF.normalize(hr_tensor, mean=[0.5]*self.channels, std=[0.5]*self.channels)  # [-1, 1]
        
        return lr_tensor, hr_tensor
    
class PairedImageDataset(Dataset):
    """
    è‡ªå®šä¹‰æ•°æ®é›†ï¼Œç”¨äºåŠ è½½æˆå¯¹çš„åŸå§‹å›¾åƒå’Œè¶…åˆ†è¾¨ç‡å›¾åƒã€‚
    """
    def __init__(self, lr_dir: str, hr_dir: str, transform=None):
        """
        åˆå§‹åŒ–æ•°æ®é›†ã€‚
        Args:
            lr_dir (str): ä½åˆ†è¾¨ç‡å›¾åƒï¼ˆoriginï¼‰çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
            hr_dir (str): é«˜åˆ†è¾¨ç‡å›¾åƒï¼ˆhrï¼‰çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
            transform (callable, optional): åº”ç”¨äºå›¾åƒçš„è½¬æ¢æ“ä½œã€‚
        """
        self.lr_dir = lr_dir
        self.hr_dir = hr_dir
        self.transform = transform
        
        # è·å–æ‰€æœ‰ä½åˆ†è¾¨ç‡å›¾åƒçš„æ–‡ä»¶ååˆ—è¡¨ï¼Œå¹¶æ’åºä»¥ç¡®ä¿é¡ºåºä¸€è‡´
        self.image_files = sorted(os.listdir(lr_dir))

    def __len__(self):
        """
        è¿”å›æ•°æ®é›†ä¸­æ ·æœ¬çš„æ€»æ•°ã€‚
        """
        return len(self.image_files)

    def __getitem__(self, idx):
        """
        æ ¹æ®ç´¢å¼•idxè·å–ä¸€å¯¹å›¾åƒã€‚
        """
        # è·å–æ–‡ä»¶å
        img_name = self.image_files[idx]
        
        # æ„å»ºä½åˆ†è¾¨ç‡å’Œé«˜åˆ†è¾¨ç‡å›¾åƒçš„å®Œæ•´è·¯å¾„
        lr_path = os.path.join(self.lr_dir, img_name)
        hr_path = os.path.join(self.hr_dir, img_name)
        
        # ä½¿ç”¨Pillowåº“æ‰“å¼€å›¾åƒ
        lr_image = Image.open(lr_path)
        hr_image = Image.open(hr_path)
        
        # ğŸ”¥ é…å¯¹å˜æ¢ï¼šç¡®ä¿LRå’ŒHRä½¿ç”¨ç›¸åŒçš„éšæœºå‚æ•°
        if self.transform:
            lr_image, hr_image = self.transform(lr_image, hr_image)

        return lr_image, hr_image, img_name

# ç›´æ¥è¿è¡Œä¼šä¸‹è½½é»˜è®¤æ•°æ®é›†MNIST
# å‡½æ•° get_dataloader ä¸ºé»˜è®¤åŠ è½½MNISTæ•°æ®é›†
def download_dataset():
    mnist = torchvision.datasets.MNIST(root='./data/mnist', download=True)
    print('length of MNIST', len(mnist))
    id = 4
    img, label = mnist[id]
    print(img)
    print(label)

    # On computer with monitor
    # img.show()

    img.save('work_dirs/tmp.jpg')
    tensor = ToTensor()(img)
    print(tensor.shape)
    print(tensor.max())
    print(tensor.min())


def get_dataloader(batch_size: int):
    transform = Compose([ToTensor(), Lambda(lambda x: (x - 0.5) * 2)])
    dataset = torchvision.datasets.MNIST(root='./data/mnist',
                                         transform=transform)
    return DataLoader(dataset, batch_size=batch_size, shuffle=True)

# è¿™é‡Œä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†ï¼Œä½ å¯ä»¥åœ¨æ–‡ä»¶é¡¶éƒ¨è®¾ç½®ä¸‰é¡¹è¶…å‚
IMAGE_ROOT = 'D:/æ·±åº¦å­¦ä¹ æ¡†æ¶/DDPM/butterfly_images_for_training'  # æ”¹æˆä½ çš„æœ¬åœ°ç›®å½•
IMAGE_SIZE = 400                                # ç»Ÿä¸€ç¼©æ”¾/è£å‰ªåˆ°è¿™ä¸ªå°ºå¯¸
CHANNELS   = 1                                  # ç°åº¦=1ï¼Œå½©è‰²=3


def set_image_shape(image_size: int, channels: int) -> None:
    global IMAGE_SIZE, CHANNELS
    IMAGE_SIZE = image_size
    CHANNELS = channels


def _build_transform(image_size=IMAGE_SIZE, channels=CHANNELS, augment=False):
    """
    æ„å»ºå›¾åƒå˜æ¢ç®¡é“
    Args:
        image_size: ç›®æ ‡å›¾åƒå°ºå¯¸
        channels: é€šé“æ•°ï¼ˆ1=ç°åº¦ï¼Œ3=RGBï¼‰
        augment: æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼ºï¼ˆè®­ç»ƒæ—¶Trueï¼Œè¯„ä¼°æ—¶Falseï¼‰
    """
    # å…ˆæŠŠ PIL å›¾åƒè½¬åˆ°æŒ‡å®šé€šé“æ•°ï¼Œå†åšå°ºå¯¸ä¸å½’ä¸€åŒ–ï¼ˆ[-1,1]ï¼‰
    color_tf = (
        Identity()
        if channels == 1 else
        ConvertToRGB()
    )
    
    # åŸºç¡€å˜æ¢ï¼ˆå§‹ç»ˆåº”ç”¨ï¼‰
    base_transforms = [
        color_tf,
        T.Resize(image_size, interpolation=Image.BICUBIC),
        T.CenterCrop(image_size),
    ]
    
    # æ•°æ®å¢å¼ºå˜æ¢ï¼ˆä»…è®­ç»ƒæ—¶ï¼‰
    if augment:
        augmentation_transforms = [
            T.RandomHorizontalFlip(0.5),    # 50%æ¦‚ç‡æ°´å¹³ç¿»è½¬
            T.RandomAffine(                 # éšæœºå¹³ç§»
                degrees=0,                  # ä¸é¢å¤–æ—‹è½¬
                translate=(0.05, 0.05),     # æœ€å¤šå¹³ç§»5%ï¼ˆçº¦5åƒç´ ï¼‰
                fill=0                      # å¡«å……é»‘è‰²ï¼ˆèƒŒæ™¯è‰²ï¼‰
            ),
        ]
        base_transforms.extend(augmentation_transforms)
    
    # å½’ä¸€åŒ–å˜æ¢ï¼ˆå§‹ç»ˆåº”ç”¨ï¼‰
    base_transforms.extend([
        T.ToTensor(),                                  # [0,1]
        T.Normalize(mean=[0.5]*channels, std=[0.5]*channels)  # -> [-1,1]
    ])
    
    return T.Compose(base_transforms)

def get_dataloader1(batch_size: int,
                   root: str = IMAGE_ROOT,
                   image_size: int = IMAGE_SIZE,
                   channels: int = CHANNELS,
                   num_workers: int = 16):
    set_image_shape(image_size, channels)
    transform = _build_transform(image_size, channels)
    dataset = torchvision.datasets.ImageFolder(root=root, transform=transform)
    return DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
        persistent_workers=(num_workers > 0),
        prefetch_factor=4
    )

def get_paired_dataloader(batch_size: int,
                          lr_root: str,
                          hr_root: str,
                          image_size: int = IMAGE_SIZE,
                          channels: int = CHANNELS,
                          num_workers: int = 16,  # åœ¨Windowsä¸Šå»ºè®®è®¾ä¸º0æˆ–1ï¼ŒLinuxä¸Šå¯ä»¥æ›´é«˜
                          augment: bool = False): # æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼ºï¼ˆè®­ç»ƒæ—¶Trueï¼Œè¯„ä¼°æ—¶Falseï¼‰
    """
    åŸºäºè‡ªå®šä¹‰çš„PairedImageDatasetåˆ›å»ºå¹¶è¿”å›ä¸€ä¸ªDataLoaderã€‚
    Args:
        batch_size (int): æ‰¹å¤„ç†å¤§å°ã€‚
        lr_root (str): ä½åˆ†è¾¨ç‡å›¾åƒæ–‡ä»¶å¤¹çš„æ ¹ç›®å½•ã€‚
        hr_root (str): é«˜åˆ†è¾¨ç‡å›¾åƒæ–‡ä»¶å¤¹çš„æ ¹ç›®å½•ã€‚
        augment (bool): æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼ºï¼ˆè®­ç»ƒæ—¶Trueï¼Œè¯„ä¼°æ—¶Falseï¼‰
        ... å…¶ä»–å‚æ•°
    """
    set_image_shape(image_size, channels)
    
    # ğŸ”¥ ä½¿ç”¨é…å¯¹å˜æ¢ï¼Œç¡®ä¿LRå’ŒHRå¯¹é½
    transform = PairedTransform(image_size, channels, augment=augment)
    
    # ä½¿ç”¨æˆ‘ä»¬è‡ªå®šä¹‰çš„Dataset
    dataset = PairedImageDataset(
        lr_dir=lr_root, 
        hr_dir=hr_root, 
        transform=transform
    )
    
    return DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
        persistent_workers=(num_workers > 0),
        prefetch_factor=4 if num_workers > 0 else 2
    )

def get_img_shape():
    # å› ä¸ºä¸Šé¢çš„ transform å¼ºåˆ¶æˆå›ºå®šå°ºå¯¸ä¸é€šé“ï¼Œç›´æ¥è¿”å›å³å¯
    return (CHANNELS, IMAGE_SIZE, IMAGE_SIZE)

if __name__ == '__main__':
    import os
    os.makedirs('work_dirs', exist_ok=True)
    download_dataset()
