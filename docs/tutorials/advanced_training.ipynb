{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 高级训练脚本拆解：SR_train.py\n",
    "\n",
    "本文档逐段引用 `SR_train.py` 的源码，按照执行顺序进行讲解，帮助你理解训练流程的每个关键环节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 自动定位项目根目录并加入 `sys.path`\n",
    "\n",
    "确保 Notebook 能直接导入仓库内的模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "项目根目录: d:\\我的工作\\深度学习框架\\sdforTFMSR\\codex---srtfm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "def 找到项目根目录(起点: Path) -> Path:\n",
    "    for parent in [起点, *起点.parents]:\n",
    "        if (parent / \"SR_train.py\").exists() and (parent / \"configs\").is_dir():\n",
    "            return parent\n",
    "    raise FileNotFoundError(\"未找到项目根目录，请确认 Notebook 位于仓库内部。\")\n",
    "\n",
    "PROJECT_ROOT = 找到项目根目录(Path.cwd())\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"项目根目录:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 头部导入与模型配置映射\n",
    "\n",
    "脚本首先引入训练所需的标准库、第三方库以及模型配置表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff99da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import cm\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "from torchmetrics.functional import peak_signal_noise_ratio\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import get_h5_dataloader\n",
    "from ddpm_simple import DDPM\n",
    "from ddim import DDIM\n",
    "from network import (build_network, convnet_big_cfg, convnet_medium_cfg,\n",
    "                     convnet_small_cfg, unet_1_cfg, unet_res_cfg)\n",
    "\n",
    "\n",
    "MODEL_CONFIGS: Dict[str, Dict[str, Any]] = {\n",
    "    \"convnet_small\": convnet_small_cfg,\n",
    "    \"convnet_medium\": convnet_medium_cfg,\n",
    "    \"convnet_big\": convnet_big_cfg,\n",
    "    \"unet\": unet_1_cfg,\n",
    "    \"unet_res\": unet_res_cfg,\n",
    "}\n",
    "\n",
    "DEFAULT_CONFIG_PATH = Path(\"configs/sr_train.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码导入了训练过程中会用到的所有依赖，并建立 `MODEL_CONFIGS` 映射，方便根据配置选择不同的骨干网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 配置加载与目录工具\n",
    "\n",
    "负责读取 JSON、创建目录以及替换文件（解决 Windows 文件锁问题）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059febfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(path: Path) -> Dict[str, Any]:\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as handle:\n",
    "        return json.load(handle)\n",
    "\n",
    "\n",
    "def ensure_dir(path: Path) -> None:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def safe_replace(src: Path, dst: Path, retries: int = 5, delay: float = 0.1) -> None:\n",
    "    \"\"\"解决 Windows 替换文件时的锁文件问题。\"\"\"\n",
    "    last_error: Optional[Exception] = None\n",
    "    for _ in range(max(1, retries)):\n",
    "        try:\n",
    "            os.replace(src, dst)\n",
    "            return\n",
    "        except PermissionError as exc:\n",
    "            last_error = exc\n",
    "            if dst.exists():\n",
    "                try:\n",
    "                    dst.unlink()\n",
    "                except PermissionError:\n",
    "                    time.sleep(delay)\n",
    "            time.sleep(delay)\n",
    "    raise last_error if last_error else PermissionError(f\"Failed to replace {dst}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 随机种子与设备解析\n",
    "\n",
    "`set_seed` 统一控制随机数生成器；`resolve_device` 自动选择 GPU/CPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ebac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: Optional[int]) -> None:\n",
    "    if seed is None:\n",
    "        return\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def resolve_device(preferred: Optional[str]) -> torch.device:\n",
    "    if preferred is None:\n",
    "        preferred = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    device = torch.device(preferred)\n",
    "    if device.type == \"cuda\" and not torch.cuda.is_available():\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. EMA 更新与学习率调度\n",
    "\n",
    "这部分保证训练稳定性：EMA 平滑权重，`warmup_cosine` 控制学习率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7722f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def ema_update(ema_model: nn.Module, model: nn.Module, decay: float) -> None:\n",
    "    ema_sd = ema_model.state_dict()\n",
    "    model_sd = model.state_dict()\n",
    "    for key, value in model_sd.items():\n",
    "        ema_sd[key].mul_(decay).add_(value, alpha=1 - decay)\n",
    "    ema_model.load_state_dict(ema_sd)\n",
    "\n",
    "\n",
    "def warmup_cosine(optimizer: torch.optim.Optimizer,\n",
    "                  current_epoch: int,\n",
    "                  max_epoch: int,\n",
    "                  lr_min: float = 0.0,\n",
    "                  lr_max: float = 1e-4,\n",
    "                  warmup_epoch: int = 10) -> None:\n",
    "    if current_epoch < warmup_epoch:\n",
    "        lr = lr_max * current_epoch / warmup_epoch\n",
    "    else:\n",
    "        lr = lr_min + (lr_max - lr_min) * (1 + math.cos(math.pi * (current_epoch - warmup_epoch) / (max_epoch - warmup_epoch))) / 2\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 可视化辅助函数\n",
    "\n",
    "用于将张量转换为可视化的彩色图像，并保存预览图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5352d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_jet(x: torch.Tensor,\n",
    "           vmin: Optional[float] = None,\n",
    "           vmax: Optional[float] = None,\n",
    "           bins: int = 256) -> torch.Tensor:\n",
    "    \"\"\"把单通道张量映射为 Jet 伪彩色。\"\"\"\n",
    "    squeeze_back = False\n",
    "    if x.dim() == 2:\n",
    "        x = x.unsqueeze(0).unsqueeze(0)\n",
    "        squeeze_back = True\n",
    "    elif x.dim() == 3:\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "    device = x.device\n",
    "    if vmin is None:\n",
    "        vmin = float(x.min().item())\n",
    "    if vmax is None:\n",
    "        vmax = float(x.max().item())\n",
    "    if vmax == vmin:\n",
    "        vmax = vmin + 1e-6\n",
    "\n",
    "    x_norm = (x - vmin) / (vmax - vmin)\n",
    "    x_norm = x_norm.clamp(0, 1)\n",
    "\n",
    "    lut_np = cm.get_cmap('jet', bins)(np.linspace(0, 1, bins))[:, :3]\n",
    "    lut = torch.from_numpy(lut_np).to(device=device, dtype=torch.float32)\n",
    "\n",
    "    idx = (x_norm * (bins - 1)).round().long()\n",
    "    rgb = lut[idx.squeeze(1)]\n",
    "    rgb = rgb.permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "    if squeeze_back:\n",
    "        rgb = rgb.squeeze(0)\n",
    "    return rgb\n",
    "\n",
    "\n",
    "def make_preview_grid(tensor: torch.Tensor, channels: int,\n",
    "                      nrow: int) -> torch.Tensor:\n",
    "    if channels == 1:\n",
    "        tensor = to_jet(tensor, vmin=0.0, vmax=1.0)\n",
    "    return make_grid(tensor, nrow=nrow)\n",
    "\n",
    "\n",
    "def save_grid_image(tensor: torch.Tensor, output_path: Path) -> None:\n",
    "    array = (tensor.clamp(0, 1).permute(1, 2, 0) * 255).byte().cpu().numpy()\n",
    "    if array.shape[2] == 1:\n",
    "        image = Image.fromarray(array[:, :, 0], mode='L')\n",
    "    else:\n",
    "        image = Image.fromarray(array, mode='RGB')\n",
    "    image.save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 模型构建与加载检查点\n",
    "\n",
    "根据配置选择骨干网络，搭建扩散模型，并在需要时加载已有权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8352e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(cfg: Dict[str, Any], device: torch.device) -> nn.Module:\n",
    "    model_cfg = cfg[\"model\"]\n",
    "    data_cfg = cfg[\"data\"]\n",
    "    backbone_key = model_cfg[\"backbone\"]\n",
    "    if backbone_key not in MODEL_CONFIGS:\n",
    "        raise KeyError(f\"Unknown backbone '{backbone_key}'. \"\n",
    "                       f\"Available: {', '.join(MODEL_CONFIGS)}\")\n",
    "    net_cfg = MODEL_CONFIGS[backbone_key].copy()\n",
    "    n_steps = model_cfg[\"diffusion_steps\"]\n",
    "\n",
    "    in_channels = data_cfg[\"channels\"]\n",
    "    image_size = data_cfg[\"image_size\"]\n",
    "    lr_channels = in_channels\n",
    "    if data_cfg.get(\"use_tfm_channels\", False):\n",
    "        lr_channels = 3\n",
    "\n",
    "    net = build_network(net_cfg, n_steps, in_channels, image_size, lr_channels).to(device)\n",
    "    return net\n",
    "\n",
    "\n",
    "def maybe_load_checkpoint(net: nn.Module, cfg: Dict[str, Any],\n",
    "                          device: torch.device) -> None:\n",
    "    resume_path = cfg[\"model\"].get(\"resume_checkpoint\")\n",
    "    if not resume_path:\n",
    "        return\n",
    "    checkpoint = torch.load(resume_path, map_location=device)\n",
    "    state_dict = checkpoint.get(\"ema_model_state_dict\",\n",
    "                                checkpoint.get(\"model_state_dict\", checkpoint))\n",
    "    net.load_state_dict(state_dict)\n",
    "    print(f\"Loaded weights from {resume_path}\")\n",
    "\n",
    "\n",
    "def get_image_shape_from_config(cfg: Dict[str, Any]) -> Tuple[int, int, int]:\n",
    "    \"\"\"从配置中获取图像形状 (channels, height, width)。\"\"\"\n",
    "    data_cfg = cfg[\"data\"]\n",
    "    channels = data_cfg[\"channels\"]\n",
    "    image_size = data_cfg[\"image_size\"]\n",
    "    return (channels, image_size, image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 构建训练数据加载器\n",
    "\n",
    "封装 `dataset.get_h5_dataloader`，同时处理坐标归一化与数据增强配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81922776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(cfg: Dict[str, Any]) -> torch.utils.data.DataLoader:\n",
    "    data_cfg = cfg[\"data\"]\n",
    "\n",
    "    coord_range = None\n",
    "    if data_cfg.get(\"use_tfm_channels\", False):\n",
    "        coord_range_x = tuple(data_cfg[\"coord_range_x\"]) if \"coord_range_x\" in data_cfg else (-1.0, 1.0)\n",
    "        coord_range_y = tuple(data_cfg[\"coord_range_y\"]) if \"coord_range_y\" in data_cfg else (-1.0, 1.0)\n",
    "        coord_range = (coord_range_x, coord_range_y)\n",
    "\n",
    "    return get_h5_dataloader(\n",
    "        h5_path=data_cfg[\"h5_path\"],\n",
    "        batch_size=data_cfg[\"batch_size\"],\n",
    "        lr_key=data_cfg.get(\"h5_lr_key\", \"TFM\"),\n",
    "        hr_key=data_cfg.get(\"h5_hr_key\", \"hr\"),\n",
    "        lr_dataset_name=data_cfg.get(\"h5_lr_dataset\"),\n",
    "        hr_dataset_name=data_cfg.get(\"h5_hr_dataset\"),\n",
    "        transpose_lr=data_cfg.get(\"transpose_lr\", False),\n",
    "        transpose_hr=data_cfg.get(\"transpose_hr\", False),\n",
    "        use_tfm_channels=data_cfg.get(\"use_tfm_channels\", False),\n",
    "        coord_range=coord_range,\n",
    "        augment=data_cfg.get(\"augment\", False),\n",
    "        h_flip_prob=data_cfg.get(\"h_flip_prob\", 0.5),\n",
    "        translate_prob=data_cfg.get(\"translate_prob\", 0.5),\n",
    "        max_translate_ratio=data_cfg.get(\"max_translate_ratio\", 0.05),\n",
    "        num_workers=data_cfg.get(\"num_workers\", 4),\n",
    "        shuffle=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e327d5ee",
   "metadata": {},
   "source": [
    "## 9. 主训练循环\n",
    "\n",
    "`train` 函数串联了数据加载、扩散前向、损失计算、EMA 更新、TensorBoard 记录与 checkpoint 管理，完整源码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a408b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ddpm: DDPM,\n",
    "          net: nn.Module,\n",
    "          cfg: Dict[str, Any],\n",
    "          device: torch.device,\n",
    "          ckpt_path: Path,\n",
    "          log_dir: Path) -> nn.Module:\n",
    "    data_cfg = cfg[\"data\"]\n",
    "    opt_cfg = cfg[\"optimization\"]\n",
    "    logging_cfg = cfg[\"logging\"]\n",
    "\n",
    "    writer = SummaryWriter(log_dir=str(log_dir))\n",
    "    print(f\"Start training, batch size: {data_cfg['batch_size']}, \"\n",
    "          f\"epochs: {opt_cfg['epochs']}\")\n",
    "\n",
    "    dataloader = create_dataloader(cfg)\n",
    "    net = net.to(device).train()\n",
    "    ema_net = deepcopy(net).eval().requires_grad_(False)\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        net.parameters(),\n",
    "        lr=opt_cfg[\"learning_rate\"],\n",
    "        betas=tuple(opt_cfg.get(\"betas\", (0.9, 0.99))),\n",
    "        weight_decay=opt_cfg.get(\"weight_decay\", 0.0),\n",
    "    )\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_loss_epoch = -1\n",
    "    model_best_state_dict = None\n",
    "    ema_model_best_state_dict = None\n",
    "\n",
    "    best_psnr = -float('inf')\n",
    "    best_psnr_epoch = -1\n",
    "    model_best_state_dict_by_psnr = None\n",
    "    ema_model_best_state_dict_by_psnr = None\n",
    "\n",
    "    use_amp = bool(opt_cfg.get(\"amp\", device.type == 'cuda'))\n",
    "    scaler = torch.amp.GradScaler(enabled=use_amp and device.type == \"cuda\")\n",
    "    print(f\"Using AMP: {use_amp}\")\n",
    "\n",
    "    epochs = opt_cfg[\"epochs\"]\n",
    "    warmup_epochs = opt_cfg.get(\"warmup_epochs\", max(1, epochs // 10))\n",
    "    lr_min = opt_cfg.get(\"lr_min\", optimizer.param_groups[0][\"lr\"])\n",
    "    lr_max = opt_cfg.get(\"lr_max\", optimizer.param_groups[0][\"lr\"])\n",
    "    preview_interval = logging_cfg.get(\"sample_interval\", 10)\n",
    "    preview_count = max(1, logging_cfg.get(\"num_preview_samples\", 4))\n",
    "    preview_nrow = int(preview_count**0.5)\n",
    "    preview_nrow = max(1, preview_nrow)\n",
    "\n",
    "    tic = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        pbar = tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        warmup_cosine(optimizer,\n",
    "                      epoch,\n",
    "                      epochs - 1,\n",
    "                      lr_min=lr_min,\n",
    "                      lr_max=lr_max,\n",
    "                      warmup_epoch=warmup_epochs)\n",
    "\n",
    "        for lr_images, hr_images, _ in pbar:\n",
    "            lr_images = lr_images.to(device, non_blocking=True)\n",
    "            hr_images = hr_images.to(device, non_blocking=True)\n",
    "            batch_size = hr_images.size(0)\n",
    "\n",
    "            t = torch.randint(0,\n",
    "                              ddpm.n_steps, (batch_size,),\n",
    "                              device=device,\n",
    "                              dtype=torch.long)\n",
    "            eps = torch.randn_like(hr_images)\n",
    "            x_t = ddpm.sample_forward(hr_images, t, eps)\n",
    "\n",
    "            with torch.amp.autocast(device_type=device.type,\n",
    "                                    dtype=torch.float16,\n",
    "                                    enabled=use_amp\n",
    "                                    and device.type == \"cuda\"):\n",
    "                eps_theta = net(x_t, t, lr_images)\n",
    "                loss = loss_fn(eps_theta, eps)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            if use_amp and device.type == \"cuda\":\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * batch_size\n",
    "            ema_update(ema_net, net, decay=opt_cfg[\"ema_decay\"])\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        mean_psnr = None\n",
    "        if (epoch + 0) % preview_interval == 0:\n",
    "            net_was_training = net.training\n",
    "            net.eval()\n",
    "            ema_net.eval()\n",
    "            with torch.inference_mode():\n",
    "                preview_batch = min(preview_count, lr_images.size(0))\n",
    "                lr_subset = lr_images[:preview_batch]\n",
    "                img_shape = get_image_shape_from_config(cfg)\n",
    "                img_net = ddpm.sample_backward_sr((preview_batch, *img_shape),\n",
    "                                                  net,\n",
    "                                                  lr_subset,\n",
    "                                                  device=device,\n",
    "                                                  simple_var=True).cpu()\n",
    "                img_ema = ddpm.sample_backward_sr((preview_batch, *img_shape),\n",
    "                                                  ema_net,\n",
    "                                                  lr_subset,\n",
    "                                                  device=device,\n",
    "                                                  simple_var=True).cpu()\n",
    "            if net_was_training:\n",
    "                net.train()\n",
    "\n",
    "            hr_subset = hr_images[:preview_batch].cpu()\n",
    "            sr01 = ((img_ema + 1) / 2).clamp(0, 1)\n",
    "            hr01 = ((hr_subset + 1) / 2).clamp(0, 1)\n",
    "\n",
    "            psnr_scores = []\n",
    "            for idx in range(sr01.size(0)):\n",
    "                psnr_val = peak_signal_noise_ratio(sr01[idx].unsqueeze(0),\n",
    "                                                   hr01[idx].unsqueeze(0),\n",
    "                                                   data_range=1.0)\n",
    "                psnr_scores.append(psnr_val.item())\n",
    "            if psnr_scores:\n",
    "                mean_psnr = float(sum(psnr_scores) / len(psnr_scores))\n",
    "\n",
    "            channels = img_shape[0]\n",
    "            lr01 = ((lr_subset.detach().cpu().clamp(-1, 1) + 1) / 2)\n",
    "            hr01_display = ((hr_subset.clamp(-1, 1) + 1) / 2)\n",
    "            net01 = ((img_net.detach().cpu().clamp(-1, 1) + 1) / 2)\n",
    "            ema01 = ((img_ema.detach().cpu().clamp(-1, 1) + 1) / 2)\n",
    "            writer.add_image(f'sample/epoch_{epoch + 1}_lr',\n",
    "                             make_preview_grid(lr01, channels, preview_nrow),\n",
    "                             epoch + 1)\n",
    "            writer.add_image(f'sample/epoch_{epoch + 1}_hr',\n",
    "                             make_preview_grid(hr01_display, channels, preview_nrow),\n",
    "                             epoch + 1)\n",
    "            writer.add_image(f'sample/epoch_{epoch + 1}_net',\n",
    "                             make_preview_grid(net01, channels, preview_nrow),\n",
    "                             epoch + 1)\n",
    "            writer.add_image(f'sample/epoch_{epoch + 1}_ema',\n",
    "                             make_preview_grid(ema01, channels, preview_nrow),\n",
    "                             epoch + 1)\n",
    "\n",
    "            if mean_psnr is not None and mean_psnr > best_psnr:\n",
    "                best_psnr = mean_psnr\n",
    "                best_psnr_epoch = epoch + 1\n",
    "                model_best_state_dict_by_psnr = deepcopy(net.state_dict())\n",
    "                ema_model_best_state_dict_by_psnr = deepcopy(\n",
    "                    ema_net.state_dict())\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader.dataset)\n",
    "        writer.add_scalar('train/loss', avg_loss, epoch + 1)\n",
    "        if mean_psnr is not None:\n",
    "            writer.add_scalar('val/psnr_mean', mean_psnr, epoch + 1)\n",
    "\n",
    "        toc = time.time()\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{epochs} finished. \"\n",
    "            f\"Average loss: {avg_loss:.6f}. \"\n",
    "            f\"Elapsed: {(toc - tic):.2f}s\")\n",
    "\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            best_loss_epoch = epoch + 1\n",
    "            model_best_state_dict = deepcopy(net.state_dict())\n",
    "            ema_model_best_state_dict = deepcopy(ema_net.state_dict())\n",
    "\n",
    "            ckpt_best = {\n",
    "                'epoch': best_loss_epoch,\n",
    "                'ema_decay': opt_cfg[\"ema_decay\"],\n",
    "                'best_loss': best_loss,\n",
    "                'model_best_state_dict': model_best_state_dict,\n",
    "                'ema_model_best_state_dict': ema_model_best_state_dict,\n",
    "            }\n",
    "            best_path = ckpt_path.with_name(f\"{ckpt_path.stem}_best.pth\")\n",
    "            tmp_best = best_path.with_suffix(best_path.suffix + \".tmp\")\n",
    "            torch.save(ckpt_best, tmp_best)\n",
    "            safe_replace(tmp_best, best_path)\n",
    "\n",
    "        ckpt = {\n",
    "            'epoch': epoch + 1,\n",
    "            'ema_decay': opt_cfg[\"ema_decay\"],\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'ema_model_state_dict': ema_net.state_dict(),\n",
    "            'best_loss': best_loss,\n",
    "            'best_loss_epoch': best_loss_epoch,\n",
    "            'model_best_state_dict': model_best_state_dict,\n",
    "            'ema_model_best_state_dict': ema_model_best_state_dict,\n",
    "            'best_psnr': best_psnr,\n",
    "            'best_psnr_epoch': best_psnr_epoch,\n",
    "            'model_best_state_dict_by_psnr': model_best_state_dict_by_psnr,\n",
    "            'ema_model_best_state_dict_by_psnr':\n",
    "            ema_model_best_state_dict_by_psnr,\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }\n",
    "        tmp_ckpt = ckpt_path.with_suffix(ckpt_path.suffix + \".tmp\")\n",
    "        torch.save(ckpt, tmp_ckpt)\n",
    "        safe_replace(tmp_ckpt, ckpt_path)\n",
    "\n",
    "    writer.close()\n",
    "    print(\"Done training!\")\n",
    "    return ema_net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44d882e",
   "metadata": {},
   "source": [
    "这段代码涵盖了核心训练流程：噪声前向、损失计算、AMP 控制、EMA 更新、指标记录以及模型保存，建议逐行对照理解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 采样与预览工具\n",
    "\n",
    "包括生成预览图、运行 DDPM / DDIM 采样器以及抓取预览 batch。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e72e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_imgs(ddpm: DDPM,\n",
    "                net: nn.Module,\n",
    "                lr_images: torch.Tensor,\n",
    "                output_path: Path,\n",
    "                device: torch.device,\n",
    "                nrow: int,\n",
    "                cfg: Dict[str, Any],\n",
    "                simple_var: bool = True) -> None:\n",
    "    net = net.to(device).eval()\n",
    "    with torch.no_grad():\n",
    "        img_shape = get_image_shape_from_config(cfg)\n",
    "        shape = (lr_images.size(0), *img_shape)\n",
    "        samples = ddpm.sample_backward_sr(shape,\n",
    "                                          net,\n",
    "                                          lr_images.to(device),\n",
    "                                          device=device,\n",
    "                                          simple_var=simple_var).cpu()\n",
    "        samples = ((samples + 1) / 2).clamp(0, 1)\n",
    "    grid = make_preview_grid(samples, img_shape[0], nrow)\n",
    "    save_grid_image(grid, output_path)\n",
    "\n",
    "\n",
    "def sample_imgs_ddim(ddim: DDIM,\n",
    "                     net: nn.Module,\n",
    "                     lr_images: torch.Tensor,\n",
    "                     output_path: Path,\n",
    "                     device: torch.device,\n",
    "                     nrow: int,\n",
    "                     cfg: Dict[str, Any],\n",
    "                     ddim_step: int = 50,\n",
    "                     eta: float = 0.0,\n",
    "                     simple_var: bool = True) -> None:\n",
    "    net = net.to(device).eval()\n",
    "    with torch.no_grad():\n",
    "        img_shape = get_image_shape_from_config(cfg)\n",
    "        shape = (lr_images.size(0), *img_shape)\n",
    "        samples = ddim.sample_backward_sr(shape,\n",
    "                                          net,\n",
    "                                          lr_images.to(device),\n",
    "                                          device=device,\n",
    "                                          simple_var=simple_var,\n",
    "                                          ddim_step=ddim_step,\n",
    "                                          eta=eta).cpu()\n",
    "        samples = ((samples + 1) / 2).clamp(0, 1)\n",
    "    grid = make_preview_grid(samples, img_shape[0], nrow)\n",
    "    save_grid_image(grid, output_path)\n",
    "\n",
    "\n",
    "def collect_preview_batch(cfg: Dict[str, Any],\n",
    "                          device: torch.device,\n",
    "                          count: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    dataloader = create_dataloader(cfg)\n",
    "    lr_images, hr_images, _ = next(iter(dataloader))\n",
    "    lr_images = lr_images[:count].to(device)\n",
    "    hr_images = hr_images[:count].to(device)\n",
    "    return lr_images, hr_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 命令行入口：`parse_args` 与 `main`\n",
    "\n",
    "处理命令行参数，选择训练或采样模式，完成最终流程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1172cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args() -> argparse.Namespace:\n",
    "    parser = argparse.ArgumentParser(description=\"Train SR diffusion model.\")\n",
    "    parser.add_argument(\"--config\",\n",
    "                        type=Path,\n",
    "                        default=DEFAULT_CONFIG_PATH,\n",
    "                        help=\"Path to training configuration JSON file.\")\n",
    "    parser.add_argument(\"--mode\",\n",
    "                        choices=[\"train\", \"sample\"],\n",
    "                        default=\"train\",\n",
    "                        help=\"Run training or sampling only.\")\n",
    "    parser.add_argument(\"--sampler\",\n",
    "                        choices=[\"ddpm\", \"ddim\"],\n",
    "                        default=None,\n",
    "                        help=\"Sampler to use in sample mode.\")\n",
    "    parser.add_argument(\"--checkpoint\",\n",
    "                        type=Path,\n",
    "                        default=None,\n",
    "                        help=\"Override checkpoint path when sampling.\")\n",
    "    parser.add_argument(\"--ddim-steps\",\n",
    "                        type=int,\n",
    "                        default=None,\n",
    "                        help=\"DDIM steps when sampling.\")\n",
    "    parser.add_argument(\"--eta\",\n",
    "                        type=float,\n",
    "                        default=None,\n",
    "                        help=\"DDIM ETA when sampling.\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    args = parse_args()\n",
    "    cfg = load_config(args.config)\n",
    "    seed = cfg.get(\"seed\", 42)\n",
    "    if seed is not None:\n",
    "        set_seed(seed)\n",
    "    else:\n",
    "        print(\"Seed disabled; results will vary between runs.\")\n",
    "\n",
    "    device = resolve_device(cfg.get(\"device\"))\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    net = build_model(cfg, device)\n",
    "    maybe_load_checkpoint(net, cfg, device)\n",
    "\n",
    "    n_steps = cfg[\"model\"][\"diffusion_steps\"]\n",
    "    ddpm = DDPM(device, n_steps)\n",
    "    ddim = DDIM(device, n_steps)\n",
    "\n",
    "    ckpt_dir = Path(cfg[\"model\"][\"checkpoint_dir\"])\n",
    "    ensure_dir(ckpt_dir)\n",
    "    ckpt_path = ckpt_dir / cfg[\"model\"][\"checkpoint_name\"]\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    log_cfg = cfg[\"logging\"]\n",
    "    log_root = Path(log_cfg[\"tensorboard_root\"])\n",
    "    ensure_dir(log_root)\n",
    "    log_dir = log_root / f\"{timestamp}-{log_cfg.get('experiment_name', 'sr-train')}\"\n",
    "    ensure_dir(log_dir)\n",
    "\n",
    "    if args.mode == \"train\":\n",
    "        ema_model = train(ddpm, net, cfg, device, ckpt_path, log_dir)\n",
    "        if log_cfg.get(\"save_preview_images\", False):\n",
    "            preview_dir = Path(log_cfg.get(\"preview_dir\", \"SR/previews\"))\n",
    "            ensure_dir(preview_dir)\n",
    "            preview_count = max(1, log_cfg.get(\"num_preview_samples\", 4))\n",
    "            nrow = max(1, int(preview_count**0.5))\n",
    "            lr_batch, _ = collect_preview_batch(cfg, device, preview_count)\n",
    "            preview_path = preview_dir / f\"{timestamp}_ema_ddpm.png\"\n",
    "            sample_imgs(ddpm,\n",
    "                        ema_model,\n",
    "                        lr_batch,\n",
    "                        preview_path,\n",
    "                        device,\n",
    "                        nrow,\n",
    "                        cfg,\n",
    "                        simple_var=cfg[\"sampler\"].get(\"simple_var\", True))\n",
    "    else:\n",
    "        ckpt_to_use = args.checkpoint or cfg[\"model\"].get(\"checkpoint_path\")\n",
    "        checkpoint = torch.load(ckpt_to_use, map_location=device)\n",
    "        state_dict = checkpoint.get(\"ema_model_state_dict\",\n",
    "                                    checkpoint.get(\"model_state_dict\",\n",
    "                                                   checkpoint))\n",
    "        net.load_state_dict(state_dict)\n",
    "        net.eval()\n",
    "\n",
    "        sampler_type = args.sampler or cfg[\"sampler\"].get(\"type\", \"ddim\")\n",
    "        preview_count = max(1, cfg[\"logging\"].get(\"num_preview_samples\", 4))\n",
    "        nrow = max(1, int(preview_count**0.5))\n",
    "        lr_batch, _ = collect_preview_batch(cfg, device, preview_count)\n",
    "        preview_dir = Path(cfg[\"logging\"].get(\"preview_dir\", \"SR/previews\"))\n",
    "        ensure_dir(preview_dir)\n",
    "        if sampler_type == \"ddpm\":\n",
    "            output_path = preview_dir / f\"{timestamp}_sample_ddpm.png\"\n",
    "            sample_imgs(ddpm,\n",
    "                        net,\n",
    "                        lr_batch,\n",
    "                        output_path,\n",
    "                        device,\n",
    "                        nrow,\n",
    "                        cfg,\n",
    "                        simple_var=cfg[\"sampler\"].get(\"simple_var\", True))\n",
    "        else:\n",
    "            output_path = preview_dir / f\"{timestamp}_sample_ddim.png\"\n",
    "            ddim_steps = args.ddim_steps or cfg[\"sampler\"].get(\"ddim_steps\", 50)\n",
    "            eta = args.eta if args.eta is not None else cfg[\"sampler\"].get(\n",
    "                \"eta\", 0.0)\n",
    "            sample_imgs_ddim(ddim,\n",
    "                             net,\n",
    "                             lr_batch,\n",
    "                             output_path,\n",
    "                             device,\n",
    "                             nrow,\n",
    "                             cfg,\n",
    "                             ddim_step=ddim_steps,\n",
    "                             eta=eta,\n",
    "                             simple_var=cfg[\"sampler\"].get(\n",
    "                                 \"simple_var\", False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 实战示例：加载配置并实例化模型\n",
    "\n",
    "通过执行下面的代码，可以确认配置、模型构建是否正常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SR_train as sr_train\n",
    "import torch\n",
    "\n",
    "训练配置 = sr_train.load_config(PROJECT_ROOT / \"configs/sr_train.json\")\n",
    "print(\"数据批大小:\", 训练配置[\"data\"][\"batch_size\"])\n",
    "print(\"骨干网络:\", 训练配置[\"model\"][\"backbone\"])\n",
    "print(\"训练轮数:\", 训练配置[\"optimization\"][\"epochs\"])\n",
    "\n",
    "设备 = torch.device(\"cpu\")\n",
    "模型 = sr_train.build_model(训练配置, 设备)\n",
    "参数总量 = sum(p.numel() for p in 模型.parameters())\n",
    "print(\"模型类型:\", 模型.__class__.__name__)\n",
    "print(f\"参数总量: {参数总量 / 1e6:.2f} M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 镜像学习率调度轨迹\n",
    "\n",
    "用虚拟参数搭建优化器，观察 `warmup_cosine` 的实际输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "优化配置 = 训练配置[\"optimization\"]\n",
    "虚拟参数 = torch.nn.Parameter(torch.zeros(1))\n",
    "优化器 = torch.optim.AdamW([虚拟参数], lr=优化配置[\"learning_rate\"])\n",
    "\n",
    "总轮数 = 优化配置[\"epochs\"]\n",
    "最小学习率 = 优化配置.get(\"lr_min\", 优化器.param_groups[0][\"lr\"])\n",
    "最大学习率 = 优化配置.get(\"lr_max\", 优化器.param_groups[0][\"lr\"])\n",
    "预热轮数 = 优化配置.get(\"warmup_epochs\", max(1, 总轮数 // 10))\n",
    "\n",
    "学习率轨迹 = []\n",
    "for epoch in range(min(总轮数, 100)):\n",
    "    sr_train.warmup_cosine(\n",
    "        优化器,\n",
    "        current_epoch=epoch,\n",
    "        max_epoch=总轮数 - 1,\n",
    "        lr_min=最小学习率,\n",
    "        lr_max=最大学习率,\n",
    "        warmup_epoch=预热轮数,\n",
    "    )\n",
    "    学习率轨迹.append(优化器.param_groups[0][\"lr\"])\n",
    "\n",
    "取样位置 = [0, min(预热轮数 - 1, len(学习率轨迹) - 1), len(学习率轨迹)//2, len(学习率轨迹) - 1]\n",
    "for idx in 取样位置:\n",
    "    print(f\"第 {idx + 1:4d} 步学习率: {学习率轨迹[idx]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 小结\n",
    "\n",
    "- `SR_train.py` 将数据、模型、优化器、日志与采样流程整合在一起；\n",
    "- 本 Notebook 以源码段落的形式呈现，方便对照阅读和修改；\n",
    "- 建议结合 `docs/training_guide.md` 与 `docs/architecture.md`，进一步理解网络设计与训练策略；\n",
    "- 若需要生成动图，可继续学习 `docs/tutorials/visualization.ipynb`。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
